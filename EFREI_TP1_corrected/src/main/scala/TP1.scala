import scala.collection.MapView
import scala.io.BufferedSource

object TP1 {
  /**
   * Answer question from 1 to 3
   * A) first using : match, case, ::, Nil or foldLeft
   * B) then using method of the List collection
   *
   * To run all the tests after your answer, type the command sbt test in the IntelliJ terminal
   * Example :
   * - type "sbt test" without the " in the terminal
   * - You will see that there is 11 TESTS FAILED
   * - Now write "Hello" instead of the ??? in the giveMeHelloString function
   * - rerun sbt test
   * - You will see  "Tests: succeeded 1, failed 10, canceled 0, ignored 0, pending 0" and if you scroll up you will see
   * - giveMeHelloString function in yellow/green which means that the test passed successfully
   *
   * Do this to check your answer after each exercise
   */

  def giveMeHelloString : String = "Hello"

  /**
   * 1) Find the last elements of a list.
   *
   * Example :
   * scala> last(List(1, 1, 2, 3, 5, 8))
   * res0: Option[Int] = Some(8)
   */

  //TODO define lastA using : match, case, ::, Nil
  def lastA[T](list: List[T]): Option[T] = list match {
    case Nil => None
    case x :: Nil => Some(x)
    case x :: tail => lastA(tail)
  }

  //TODO define lastB using method of the List collection
  def lastB[T](list: List[T]): Option[T] = list.lastOption

  /**
   * 2) Find the Kth element of a list:
   * By convention, the first element in the list is element 0.
   *
   * Example:
   * scala> nth(2, List(1, 1, 2, 3, 5, 8))
   * res0: Option[Int] = Some(2)
   */

  //TODO define nthA using : match, case, ::, Nil
  def nthA[T](x: Int, l: List[T]): Option[T] = (x, l) match {
    //case (0, Nil) => None
    case (0, x :: tail) => Some(x)
    case (x, head :: tail) if x > 0 => nthA(x-1, tail)
    case (x, list) => None
  }

  //TODO define nthB using method of the List collection
  def nthB[T](x: Int, l: List[T]): Option[T] = if (x > 0 && x < l.length) Some(l(x)) else None

  /**
   * 3) Reverse a list:
   *
   * Example:
   * scala> reverse(List(1, 1, 2, 3, 5, 8))
   * res0: List[Int] = List(8, 5, 3, 2, 1, 1)
   */

  //TODO define reverseA using : foldLeft, ::
  def reverseA[T](list: List[T]): List[T] = list.foldLeft(List.empty[T])((acc, el) => el:: acc)

  //TODO define reverseB using method of the List collection
  def reverseB[T](list: List[T]): List[T] = list.reverse

  /**
   * 4) Sum of wages:
   * With the case class Employee defined below, find the sum of salaries from a list of employees
   *
   * Example:
   * scala> salarySum(List(Employee("Jon", 2000), Employee("Jane", 3500)))
   * res0: Double = 5500.0
   */

  case class Employee(name: String, salary: Double)

  //TODO define salarySum which is the sum of the salaries from a list of employees
  def salarySum(employees: List[Employee]): Double = {
    employees.map(employee => employee.salary).sum
  }

  /**
   * 5) Address list:
   * With the case class User defined below, list the all their addresses
   *
   * Example:
   * scala> addressOf(List(User("Jon", "5 Av. des Champs-Ã‰lysÃ©es, Paris"), User("James","17 Boulevard PoissonniÃ¨re, Paris")))
   * res0: List[String] = List("5 Av. des Champs-Ã‰lysÃ©es, Paris","17 Boulevard PoissonniÃ¨re, Paris")
   */

  case class User(name: String, address: String)

  //TODO define addressOf which gives a list of addresses from a list of users
  def addressOf(users: List[User]): List[String] = {
    users.map(user => user.address)
  }

  /**
   * 6) Define the average function :
   *
   * Example:
   * scala> average(Iterator(1, 2, 3, 4, 5, 6, 7, 8))
   * res0: Option[Double] = Some(4.5)
   */

  //TODO define average which takes an Iterator of Double in parameter
  def average(values: Iterator[Double]): Option[Double] = {
    //An Iterator does not work like a List
    //see this to have a better understanding https://docs.scala-lang.org/overviews/collections/iterators.html
    if (values.isEmpty)  None

    else {
      val res: (Int, Double) = values.foldLeft((0, 0.0)) {
        case ((count, sum), nextValue) =>
          (count + 1, sum + nextValue)
      }
      Some(res._2 / res._1)

    }
  }

  /**
   * 7) Monoids and almost MapReduce
   * This exercise comes from our blog article written by FranÃ§ois Sarradin which you can find here :
   * https://blog.univalence.io/les-monoides-ne-sont-pas-une-maladie/
   *
   * /////////////////////
   * Extract from an article :
   *
   * "un monoÃ¯de est une structure algÃ©brique correspondant Ã  un ensemble (les valeurs) avec un Ã©lÃ©ment neutre (la valeur initiale)
   * et une loi de composition interne associative (l'opÃ©ration binaire).
   * C'est souvent notÃ© (E, âœ», e), avec E l'ensemble de valeurs, âœ» la loi de composition interne et e l'Ã©lÃ©ment neutre.
   *
   * Alors, on dit loi de composition, car l'idÃ©e de notre opÃ©ration est de combiner deux Ã©lÃ©ments de notre ensemble de valeurs
   * (ie. de les composer, d'ailleurs on devrait pouvoir parler d'agrÃ©ger des valeurs).
   * On dit interne car en combinant ces deux valeurs, notre opÃ©ration retourne une nouvelle valeur
   * qui fait partie de notre ensemble initial de valeurs (ie. on ne sort pas de cet ensemble).
   *
   * Pour associative, hÃ© bien... Si nous utilisons plusieurs fois notre opÃ©ration dans une expression,
   * il est alors possible d'Ã©valuer l'expression quelque soit l'endroit oÃ¹ on commence Ã  l'Ã©valuer.
   * C'est-Ã -dire qu'avec l'expression a + b + c, je peux trÃ¨s bien commencer par x = a + b
   * et ensuite faire x + c ou commencer par x = b + c et faire a + x aprÃ¨s.
   * Au final, on note Ã§a (a + b) + c = a + (b + c). L'ordre d'Ã©valuation des sous-expressions n'a pas d'importance pour un monoÃ¯de.
   *
   * C'est une propriÃ©tÃ© intÃ©ressante, car Ã§a permet de dÃ©couper une expression en sous-expression et d'Ã©valuer ces sous-expressions en parallÃ¨le,
   * puis de rÃ©cupÃ©rer et combiner les rÃ©sultats de ces Ã©valuations pour obtenir le rÃ©sultat final...
   * Et comme Ã§a, on vient de rÃ©inventer MapReduce !"
   *
   *
   *
   * Voici une liste de stations de ski avec notamment leur localisation et une Ã©valuation sur 5.
   *
   * Nous avons ci-dessous un extrait d'une liste des stations de ski en France.
   * Bon... Ce n'est pas du big data, hein ! Mais on va faire comme si ðŸ˜¬.
   *
   * Cette liste n'est pas complÃ¨te en terme d'information.
   * MalgrÃ© Ã§a, nous allons donner la moyenne des Ã©valuations... tel que le ferait MapReduce ou Spark.
   *
   * Dans MapReduce, il y a une Ã©tape de prÃ©paration des donnÃ©es oÃ¹ on part d'un fichier pour le convertir en un ensemble clÃ©/valeur.
   *
   * /////////////////////
   */

  /*TODO
     Now, define getRatingsByDepartement, imagine reading the file "ski_stations_ratings.csv" in the folder Resources and getting an Iterable[String] for each row
     Note that the rating is in position 1 in each line and the department in position 6
   */
  import scala.util.Try

  // we want to get an Map where the key is departement and the value an iterable of all the ratings of that departement
  def getRatingsByDepartement(lines: Iterable[String]): Map[String, Iterable[Double]] = {
    // drop CSV header
    val data: Iterable[String] = lines.drop(1)

    val rows: Iterable[Array[String]] =
      data.map { line =>
        //TODO cleaning line and separate fields by the comma character
        val row: Array[String] = line.trim.split(",")

        // cleansing: if fields are missing, we pad row with empty strings
        row.padTo(7, "")
      }

    // we want an Iterable consisting of the pair Departement and Rating
    val deptRatings: Iterable[(String, Double)] =
      //TODO we remove lines with no departement
      rows.filterNot(_(6).isEmpty)
        //then we map the creation of the tuple
        .map(fields =>
          (fields(6), Try { fields(1).toDouble }.getOrElse(0.0))
        )

    deptRatings
      .groupBy { case (departement, rating) => departement }
      .view.mapValues(row => row.map { case (departement, rating) => rating }).toMap
  }

  /**
   * /////////////////////
   * From the article:
   *
   * La fonction getRatingsByDepartement exÃ©cute en fait un shuffle (ie. une redistribution des donnÃ©es)
   * en rÃ©alisant un partitionnement utilisant le dÃ©partement comme clÃ© (ce qui n'est pas la meilleure des clÃ©s,
   * dans la mesure oÃ¹ la rÃ©partition des donnÃ©es dans les diffÃ©rentes partitions sera ici dÃ©sÃ©quilibrÃ©e,
   * puisque par exemple dans les Vosges il n'y a pas beaucoup de stations contrairement Ã  la Haute-Savoie...
   * Mais, bon. Ce n'est comme si on pouvait faire du big data avec l'Ã©numÃ©ration des stations de ski en France).
   * Ici, Ã  chaque clÃ© correspond une partition des Ã©valuations.
   * Dans le cadre de MapReduce, chaque partition serait dÃ©posÃ©e dans des nÅ“uds diffÃ©rents du cluster.
   *
   * Il va maintenant falloir calculer la moyenne. En supposant, qu'on ait Ã  faire Ã  une liste immense,
   * il est plus intÃ©ressant de parcourir cette liste en une seule passe qu'en deux.
   * Car pour calculer une moyenne, il faut d'un cÃ´tÃ© une somme de valeurs et de l'autre leur quantitÃ©, avant de diviser ces deux rÃ©sultats.
   * Ce qui normalement implique deux passes sur notre dataset.
   * Pour le faire en une seule passe, nous allons calculer la somme et la quantitÃ© en mÃªme temps,
   * en stockant les rÃ©sultats intermÃ©diaires dans un couple de valeurs (somme, quantitÃ©).
   *
   * Alors, il existe diffÃ©rentes approches pour implÃ©menter ce calcul de moyenne.
   * Pour l'exercice ici, nous allons Ã©tudier une solution mettant en avant la notion de monoÃ¯de,
   * en se basant sur une typeclasse (un peu Ã  la maniÃ¨re de la bibliothÃ¨que Scala Cats).
   *
   * En Scala, pour dÃ©clarer une typeclasse Monoid, il faut dÃ©clarer un trait gÃ©nÃ©rique,
   * oÃ¹ le paramÃ¨tre A reprÃ©sente le type qui sera qualifiÃ© de monoÃ¯de.
   * Ce trait contient deux mÃ©thodes empty qui retourne l'Ã©lÃ©ment neutre et combine qui permet de combiner deux Ã©lÃ©ments de A.
   *
   * /////////////////////
   */

  trait Monoid[A] {
    def empty: A
    def combine(a: A, b: A): A
  }

  object Monoid {
    //this will allows us to write Monoid[Int].empty instead of implicitly[Monoid[Int]].empty
    @inline def apply[A](implicit ev: Monoid[A]): Monoid[A] = ev
  }

  /**
   * Let's declare a few instances of our typeclass Monoid, that will help us solve our problem
   */

  // TODO Monoid (Int, +, 0)
  implicit val intMonoid: Monoid[Int] = new Monoid[Int] {
    override def empty: Int = 0
    override def combine(a: Int, b: Int): Int = a + b
  }

  // TODO Monoid (Double, +, 0.0)
  implicit val doubleMonoid: Monoid[Double] = new Monoid[Double] {
    override def empty: Double = 0.0
    override def combine(a: Double, b: Double): Double = a + b
  }

  // TODO turn any tuple (A, B) into Monoid, providing A and B both are Monoid
  implicit def tupleMonoid[A: Monoid, B: Monoid]: Monoid[(A, B)] =
    new Monoid[(A, B)] {
      override def empty: (A, B) = (Monoid[A].empty, Monoid[B].empty)

      override def combine(left: (A, B), right: (A, B)): (A, B) =
        (Monoid[A].combine(left._1, right._1),
          Monoid[B].combine(left._2, right._2))
    }

  /**
   * Let's add to some collection the operation combineAll, in which if the values of the collection are from a monoid,
   * combine all the values in order to have only one result
   */

  implicit class iterableWithCombineAll[A: Monoid](l: Iterable[A]) {
    def combineAll: A = l.fold(Monoid[A].empty)(Monoid[A].combine)
  }

  //our MapReduce program/function
  def skiRatingAverage:Double = {
    /**
     * Let's use our function getRatingsByDepartement with a file to obtain a partionning of the data
     */

    import scala.io.Source

    val file: BufferedSource = Source.fromFile("D:\\Documents\\GitHub\\EFREI_TP1\\Resources\\ski_stations_ratings.csv")
    val partitions: Map[String, Iterable[Double]] = getRatingsByDepartement(file.getLines().to(Iterable))

    /**
     * And now let's do our MapReduce
     */

    // TODO phase 1 (Map): get ratings only and associate the value 1 to the rating (create a pair (rating,1))
    val partitionedRatingWithOne: MapView[String, Iterable[(Double, Int)]] =
    partitions.view.mapValues(ratings => ratings.map(rating => (rating, 1)))

    // TODO phase 2 (Combine): locally sum ratings and 1s for each partition
    val partitionedSumRatingsAndCount: MapView[String, (Double, Int)] =
      partitionedRatingWithOne.mapValues(data => data.combineAll)

    // TODO phase 3 (Reduce): combine for all partitions the sum of ratings and counts
    val (rating, count) =
      partitionedSumRatingsAndCount.values.combineAll

    rating / count
  }

}
